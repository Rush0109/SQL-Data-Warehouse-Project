# ğŸ“Š SQL Data Warehouse Project

**End-to-End Data Warehouse using Medallion Architecture (Bronze, Silver, Gold)**

---

## ğŸ“Œ Overview

This project demonstrates the design and implementation of a **SQL Serverâ€“based Data Warehouse** that integrates data from multiple source systems (CRM and ERP) and transforms it into **analytics-ready datasets** for reporting and decision-making.

The solution follows **Medallion Architecture** principles to clearly separate raw data ingestion, data cleansing, and business-ready analytics layers.
The project focuses on **data quality, transformation logic, and dimensional modeling**, reflecting real-world data engineering and analytics practices.

---

## ğŸ¯ Business Problem

Operational data was available as **raw CSV files** from different systems:

* **CRM system**: customer, product, and sales transactions
* **ERP system**: customer demographics, locations, and product categories

Key challenges:

* Duplicate and inconsistent customer records
* Invalid or missing dates
* Incorrect or inconsistent sales values
* No unified data model for analytics
* Manual and repetitive data preparation for reporting

The objective was to **centralize, clean, and structure the data** into a trusted data warehouse that supports fast, consistent, and reliable analytics.

---

## ğŸ—ï¸ Architecture Overview

The warehouse is designed using a **three-layer Medallion Architecture**:

### ğŸ”¹ Bronze Layer (Raw Data)

* Stores source data **as-is**
* Data ingested from CSV files using bulk load operations
* No transformations applied
* Serves as an audit and traceability layer

### ğŸ”¹ Silver Layer (Cleaned & Standardized Data)

* Applies data cleansing, validation, and standardization
* Handles:

  * Duplicate records
  * Invalid and future dates
  * Inconsistent categorical values
  * Incorrect or missing sales values
* Enforces business rules and data quality logic

### ğŸ”¹ Gold Layer (Business-Ready Data)

* Analytics-ready **star schema**
* Fact and dimension views
* Optimized for BI tools, reporting, and ad-hoc SQL queries

---

## ğŸ” Data Flow

```
Source CSV Files
   â†“
Bronze Layer (Raw Tables)
   â†“
Silver Layer (Cleaned & Standardized Tables)
   â†“
Gold Layer (Fact & Dimension Views)
   â†“
Analytics / Reporting / BI
```

---

## ğŸ—ƒï¸ Data Model (Gold Layer)

### â­ Star Schema
<img width="1920" height="993" alt="Data_mart_(Warehouse_project)" src="https://github.com/user-attachments/assets/3a29de49-f340-441a-9bb2-1fb2a2f69b8a" />


---

## âš™ï¸ Key Transformations & Logic

### ğŸ§¹ Data Cleansing

* Standardized gender, marital status, and country values
* Converted invalid date formats to `NULL`
* Removed future birthdates

### ğŸ” Deduplication

* Used `ROW_NUMBER()` window function to retain the latest customer records

### ğŸ“¦ Product Lifecycle Handling

* Used `LEAD()` window function to manage product history
* Filtered only active products in the Gold layer

### ğŸ’° Sales Validation

* Recalculated sales when values were missing or inconsistent

  ```
  sales = quantity Ã— price
  ```

---

## ğŸ§  SQL Concepts Used

* Stored Procedures
* Window Functions (`ROW_NUMBER`, `LEAD`)
* Common Table Expressions (CTEs)
* Conditional Logic (`CASE`)
* Data Type Casting & Validation
* Joins (LEFT JOIN)
* Star Schema Modeling
* ETL Design Patterns

---

## ğŸ› ï¸ Tools & Technologies

* **Database:** SQL Server
* **Language:** T-SQL
* **IDE:** SQL Server Management Studio (SSMS)
* **Data Sources:** CSV Files
* **Version Control:** GitHub

---

## ğŸ“ˆ Outcomes & Impact

* Eliminated repetitive manual data cleaning
* Created a single source of truth for analytics
* Improved data consistency and reporting reliability
* Enabled faster, cleaner, and scalable analytics queries
* Built a solid foundation for BI tools and future enhancements

---

## ğŸš€ How to Run the Project

1. Create the database and schemas (`Bronze`, `Silver`, `Gold`)
2. Load source CSV files into the Bronze layer
3. Execute Silver layer transformation stored procedure
4. Query Gold layer views for analytics and reporting

---

## ğŸ”® Future Improvements

* Implement incremental loading (CDC / watermark logic)
* Add indexes for performance optimization
* Introduce automated data quality tests
* Integrate BI tools (Power BI / Tableau)
* Add orchestration using SQL Agent or external schedulers

---

## ğŸ™Œ Credits

This project was inspired by learning resources from **DataWithBaraa**.
While the initial architectural concepts were referenced for learning, the **data model, SQL transformations, validation logic, and overall implementation were redesigned and implemented independently**.

---

## ğŸ‘¤ Author

**Rushikesh Sawant**
SQL | Data Analysis | Data Warehousing

ğŸ”— GitHub: [https://github.com/Rush0109](https://github.com/Rush0109)

---

### âœ… Why this README is strong

* Honest but confident
* Not labeled as a â€œtutorial projectâ€
* Clear ownership of implementation
* Interview-ready narrative
* Recruiter-friendly language

If you want next, I can:

* review this once you push it live
* add diagrams directly into README
* write a **short recruiter-focused README**
* help you defend this project in **interviews**

This README is **final-grade and professional**.
